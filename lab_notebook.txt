2015-11-19
----------

* After long last, I finally created a separate WoCMan repo and I am now creating this notebook.  I maintained a paper log for a long time, but I don't remember at the moment where I put it.  This notebook can also be shared with Dan, Sid, and Emery so that they can follow along with my progress.

* So to summarize: WoCMan is a set of extensions to do parameter estimation in the AutoMan framework.  E.g., having the crowd answer questions like "What is the weight of this ox?"  In contrast with AutoMan, these kinds of tasks tend to be based on innumerable probability spaces rather than enumerable probability spaces.  In other words, people may largely agree on an estimate (2.01 vs 2.009) even through their responses are not exactly the same.

* Now let's talk about how WoCMan works.  The user interface for WoCMan is much like AutoMan.  You need to supply a little more information:
  1. An AutoMan function.
  2. A statistic (which is a function of the AutoMan return value)
  3. A confidence value.
  4. A confidence interval WIDTH.

* Let me motivate the point above with the following example.  You want to know how many M&Ms are in a jar (from a picture of a jar), plus or minus 10 M&Ms.  To use WoCMan, you might have the following:
  1. The AutoMan function:
  
  val HowManyMMs = (img: Image) => freetexts[Double] {
    image = img,
    text = "How many M&Ms are in this jar?"
  }
  
  2. The statistic:
  
  def mean(X: Array[Double]) = // whatever
  
  3. The confidence value: 0.95
  
  4. The confidence width: 20

* So the WoCMan function is defined like:

  def HowMany(img: Image) = wocman {
    automan = HowManyMMs(img),
    confidence = 0.95,
    ci = 20,
    statistic = Mean
  }
  
  Since a confidence level of 0.95 and the mean are pretty standard, we can make them defaults and write:
  
  def HowMany(img: Image) = wocman {
    automan = HowManyMMs(img),
    ci = 20
  }

* Now, what happens when you call this?  Ala,

  val mms = HowManyMMs(my_picture)
  
  First, Scala runs "wocman", which is secretly a constructor, on your arguments, and it returns a WoCMan object.  What are your arguments?  Well: automan = HowManyMMs(img) and ci = 20.  Of course, it needs to evaluate HowManyMMs(img), which is a lambda, which calls "freetext", which is also a constructor.  This is how WoCMan/AutoMan controls when evaluation happens.  You're basically just calling constructors all the time.  In the background, worker threads start up to do the work.
  
  Note that the user never gave us a sample size.  WoCMan determines sample sizes automatically. To do this, it uses nonparametric bootstrap confidence interval estimation techniques (like the BCa bootstrap, described in "Bootstrap Confidence Intervals" by DiCiccio and Efron, 1996).  The beauty of these methods, as stated by DiCiccio & Efron is that "the algorithms are completely automatic, requiring no more thought for the maximum eigenvalue than the correlation coefficient or for any other parameter."  This allows us to construct reliable confidence intervals for arbitrary, user-defined statistics.  This approach allows us to specify exact confidence interval procedures for better accuracy when we recognize them (e.g., for the mean) and to have a theoretically sound fallback when we do not.  Of course, the downside of bootstrap procedures is that we always need empirical support to justify our estimates, so when using bootstrap procedures, WoCMan must always pay for some minimum, user-specified sample size.  The default sample size is the magic number 30.
  
  So a thread starts up and schedules the "how many M&Ms" job on MTurk with the default sample size.  When it comes back with some responses, the important part happens: WoCMan runs the "statistic" function on the answer and bootstrap confidence intervals, and performs the following test: is the bootstrap 1-alpha confidence interval at least as tight as the bound specified by the user?  If so, we're done, and WoCMan returns the parameter estimate and confidence interval.  If not, WoCMan obtains another sample.  The size of the new sample depends on user-specified policy.  A naive policy might be simply to double the total sample size.  Something more subtle might be based on rejecting a null hypothesis based on the current best estimate of the confidence interval along with the appropriate multiple comparisons correction.
  
  Finally, WoCMan returns the outcome, which is either an estimate of the statistic (in this case the mean) along with bootstrap confidence bounds, or else a program error along with the best estimate obtained so far (e.g., in the scenario where WoCMan runs out of money).
  
* So the important question moving forward is: what are our research questions?  The questions that motivate me are:
  1. Can a practical estimation language be built from 1) noisy crowdsourced responses and 2) without requiring deep statistical knowledge on the part of the programmer?
  2. How does it improve on the state of the art?
  3. Is the system accurate?
  4. Is the system efficient?
  5. How does it handle random-answering adversaries?
  6. Is it expressive and easy to use?
  
  I think that the following answers will satisfactorily answer the above questions:
  
  1. A working system will be existential proof that the answer is yes.
  2. We will compare against the state of the art--to our knowledge, WoCMan is the first automatic system for estimation tasks.
  3 & 4. We can answer this in a couple waus: 1) using simulation studies using parametric families with known exact estimation procedures.  Since Efron has already talked about this quite a bit, I don't think this needs to be very deep, and 2) using case studies drawn from our existing studies (e.g., school lunch surveys).
  5. As we noted before, and has been noted again recently (Gray and Suri, IIRC), random answers on MTurk are still a problem.  To what extent is WoCMan resilient to these threats to validity?  My thinking here is that we can try injecting low-quality answers into our results and see how it affects the output.  I don't have any great insights here yet, except that if answers are truly uniformly random, the only effect will be that WoCMan takes longer to deliver an answer, at least for estimates of the mean.  Other statistics may suffer.
  6. Having a small set of disparate apps that are unified by a common thread of parameter estimation would clearly demonstrate the effectiveness.  With regard to ease of use, there are two ways to attack this.  1) showing that the programs are declarative and short (ala the AutoMan paper) helps, but ideally we will 2) do a user study.  Obviously, #2 is more effort, but it is _very_ convincing.
  